{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-12T22:03:24.017540Z",
     "start_time": "2022-12-12T22:03:23.001418Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This class is specific for downloading different collaborative-filtering datasets, and building new ways of simulating user ratings for the data used in this research."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-12T22:03:24.088504Z",
     "start_time": "2022-12-12T22:03:24.024194Z"
    }
   },
   "outputs": [],
   "source": [
    "class Data:\n",
    "    \n",
    "    '''\n",
    "    The datasets for collaborative filtering must be:\n",
    "        - The dataframe containing the ratings. \n",
    "        - It must have three columns, corresponding to the user (raw) ids, \n",
    "          the item (raw) ids, and the ratings, in this order.   \n",
    "    '''\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        '''\n",
    "        The databases (ml_100k, ml_1m and jester) are built-in the surprise package for\n",
    "        collaborative-filtering\n",
    "        '''\n",
    "        \n",
    "        self.available_databases=['ml_100k', 'ml_1m','jester', 'lda_topics', 'lda_rankings', 'uniform']\n",
    "\n",
    "    def show_available_databases(self):\n",
    "        print('The avaliable database are:')\n",
    "        for i,database in enumerate(self.available_databases):\n",
    "            print(str(i)+': '+database)            \n",
    "        \n",
    "    def read_data(self,database_name):\n",
    "        self.database_name=database_name\n",
    "        self.the_data_reader= getattr(self, 'read_'+database_name.lower())\n",
    "        self.the_data_reader()   \n",
    "\n",
    "    def read_ml_100k(self):\n",
    "        \n",
    "        '''\n",
    "        Please search the surprise package for the documentation of this dataset.\n",
    "        https://grouplens.org/datasets/movielens/\n",
    "        '''\n",
    "        \n",
    "        from surprise import Dataset\n",
    "        data = Dataset.load_builtin('ml-100k')\n",
    "        self.df = pd.DataFrame(data.__dict__['raw_ratings'], columns=['user_id','item_id','rating','timestamp'])\n",
    "        self.df.drop(columns=['timestamp'],inplace=True)\n",
    "        self.df.rename({'user_id':'userID','item_id':'itemID'},axis=1,inplace=True)\n",
    "\n",
    "    def read_ml_1m(self):\n",
    "        \n",
    "        '''\n",
    "        Please search the surprise package for the documentation of this dataset.\n",
    "        https://grouplens.org/datasets/movielens/\n",
    "        '''\n",
    "        \n",
    "        from surprise import Dataset\n",
    "        data = Dataset.load_builtin('ml-1m')\n",
    "        self.df = pd.DataFrame(data.__dict__['raw_ratings'], columns=['user_id','item_id','rating','timestamp'])\n",
    "        self.df.drop(columns=['timestamp'],inplace=True)\n",
    "        self.df.rename({'user_id':'userID','item_id':'itemID'},axis=1,inplace=True)\n",
    "\n",
    "    def read_jester(self):\n",
    "        \n",
    "        '''\n",
    "        Please search the surprise package for the documentation of this dataset.\n",
    "        https://eigentaste.berkeley.edu/dataset/\n",
    "        '''\n",
    "        \n",
    "        from surprise import Dataset\n",
    "        data = Dataset.load_builtin('jester')\n",
    "        self.df = pd.DataFrame(data.__dict__['raw_ratings'], columns=['user_id','item_id','rating','timestamp'])\n",
    "        self.df.drop(columns=['timestamp'],inplace=True)\n",
    "        self.df.rename({'user_id':'userID','item_id':'itemID'},axis=1,inplace=True)\n",
    "        \n",
    "    def read_uniform(self):\n",
    "        \n",
    "        '''\n",
    "        Hyperparameters -\n",
    "        `n_users` : number of simulated users in the database;\n",
    "        `n_ratings` : number of simulated rating events in the database.\n",
    "        \n",
    "        This is a fictional dataset based in the choice of an uniformly distributed random rating \n",
    "        (from 1 to 5) for one of the simulated users of the recommender-system that is being designed in\n",
    "        this research project.\n",
    "        '''\n",
    "        n_users = 20\n",
    "        n_ratings = 10000\n",
    "        \n",
    "        import random\n",
    "        \n",
    "        opo = pd.read_csv('../oportunidades.csv')\n",
    "        df = [(random.randrange(n_users), random.randrange(len(opo)), random.randrange(1,5)) for i in range(n_ratings)]\n",
    "        self.df = pd.DataFrame(df, columns = ['userID', 'itemID', 'rating'])\n",
    "        \n",
    "    def read_lda_topics(self):\n",
    "        \n",
    "        '''\n",
    "        Hyperparameters -\n",
    "        `n_users` : number of simulated users in the database;\n",
    "        `n_ratings` : number of simulated rating events in the database.\n",
    "        \n",
    "        This first LDA based dataset builds a model with K = `n_users` topics. LDA topics\n",
    "        are used as proxies for simulated users with different clusters of interest. At first\n",
    "        a random opportunity is chosen, than the amount of a randomly chosen topic inside the description\n",
    "        is multiplied by five. The ceiling operation of this result is the rating that the fictional user\n",
    "        will give to that opportunity.\n",
    "        Because the amount of each topic predicted by the model is disollved among various topics,\n",
    "        it is very rare to find an opportunity that has a higher LDA value. The consequence is that this dataset\n",
    "        has really low volatility and the major part of ratings are equal to 1.\n",
    "        '''\n",
    "        \n",
    "        n_users = 20\n",
    "        n_ratings = 10000\n",
    "        \n",
    "        import gensim\n",
    "        import random\n",
    "        import math\n",
    "        \n",
    "        opo = pd.read_csv('../oportunidades_results.csv')\n",
    "        # opo = opo.iloc[np.where(opo['opo_brazil']=='Y')]\n",
    "        \n",
    "        try:\n",
    "            lda_model = gensim.models.ldamodel.LdaModel.load(f'models/lda_model{n_users}.model')\n",
    "        except:\n",
    "            import generate_users\n",
    "            generate_users.gen_model(n_users)\n",
    "            lda_model = gensim.models.ldamodel.LdaModel.load(f'models/lda_model{n_users}.model')\n",
    "\n",
    "        df = []\n",
    "        for i in range(n_ratings):\n",
    "            opo_n = random.randrange(len(opo))\n",
    "            txt = opo.loc[opo_n,'opo_texto']\n",
    "            opo_bow = lda_model.id2word.doc2bow(txt.split())\n",
    "            topics = lda_model.get_document_topics(opo_bow)\n",
    "            topics = {topic[0]:topic[1] for topic in topics}\n",
    "            user = random.sample(topics.keys(), 1)[0]\n",
    "            rating = math.ceil(topics[user]*5)\n",
    "            df.append((user, opo_n, rating))\n",
    "\n",
    "        self.df = pd.DataFrame(df, columns = ['userID', 'itemID', 'rating'])\n",
    "        \n",
    "    def read_lda_rankings(self):\n",
    "        \n",
    "        '''\n",
    "        Hyperparameters -\n",
    "        `n_users` : number of simulated users in the database;\n",
    "        `n_ratings` : number of simulated rating events in the database.\n",
    "        \n",
    "        This second LDA based dataset builds a model with K = `n_users` topics. LDA topics\n",
    "        are used as proxies for simulated users with different clusters of interest. At first\n",
    "        a random opportunity is chosen, than the amounts of the topics are sorted, and the rating \n",
    "        value is equal to the quintile in which the topic is located.\n",
    "        Because the ratings will be equal to the relative significance of that topic with respect\n",
    "        to the overall opportunity description, this dataset has a considerably larger volatility\n",
    "        and ratings are relatively equally occurrent.\n",
    "        '''\n",
    "        \n",
    "        n_users = 9\n",
    "        n_ratings = 5000\n",
    "        \n",
    "        import gensim\n",
    "        import random\n",
    "        import math\n",
    "        import tqdm\n",
    "        \n",
    "        opo = pd.read_csv('../oportunidades.csv')\n",
    "        # opo = opo.iloc[np.where(opo['opo_brazil']=='Y')]\n",
    "        \n",
    "        path = f'models/output_linkedin_cle_lda_model_{n_users}_topics_symmetric_alpha_auto_beta'\n",
    "        lda_model = gensim.models.ldamodel.LdaModel.load(path)\n",
    "        \n",
    "        df = []\n",
    "        \n",
    "        pbar = tqdm.tqdm(total= n_ratings)\n",
    "        for i in range(n_ratings):\n",
    "            opo_n = random.randrange(len(opo))\n",
    "            txt = opo.loc[opo_n,'opo_texto']\n",
    "            opo_bow = lda_model.id2word.doc2bow(txt.split())\n",
    "            topics = lda_model.get_document_topics(opo_bow)\n",
    "            topics = {topic[0]:topic[1] for topic in topics}\n",
    "\n",
    "            prop = pd.DataFrame([topics], index=['prop']).T.sort_values('prop', ascending=True)\n",
    "            prop['rating'] = range(1, len(prop)+1)\n",
    "            prop['rating'] = prop['rating']/len(prop)\n",
    "            prop['rating'] = prop['rating'].apply(lambda x: math.ceil(x*5))\n",
    "            prop.reset_index(inplace=True)\n",
    "\n",
    "            prop = prop.sample(1)\n",
    "\n",
    "            df.append((prop['index'].values[0], opo_n, prop['rating'].values[0]))\n",
    "            pbar.update(1)\n",
    "\n",
    "        pbar.close() \n",
    "        self.df = pd.DataFrame(df, columns = ['userID', 'itemID', 'rating'])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-12T22:03:58.127350Z",
     "start_time": "2022-12-12T22:03:24.090529Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 5000/5000 [00:31<00:00, 158.33it/s]\n"
     ]
    }
   ],
   "source": [
    "data=Data()\n",
    "data.read_data('lda_rankings')\n",
    "data.df.to_csv('simulation2.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Method class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *surprise* library provides 11 classifier models that try to predict the classification of training data based on several different *collaborative-filtering* techniques. The models provided with a brief explanation in English are mentioned below, for more information please refer to the [package documentation.](https://surprise.readthedocs.io/en/stable/prediction_algorithms_package.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*random_pred.NormalPredictor*:\n",
    "Algorithm predicting a random rating based on the distribution of the training set, which is assumed to be normal.\n",
    "\n",
    "*baseline_only.BaselineOnly*:\n",
    "Algorithm predicting the baseline estimate for given user and item.\n",
    "\n",
    "*knns.KNNBasic*:\n",
    "A basic collaborative filtering algorithm.\n",
    "\n",
    "*knns.KNNWithMeans*:\n",
    "A basic collaborative filtering algorithm, taking into account the mean ratings of each user.\n",
    "\n",
    "*knns.KNNWithZScore*:\n",
    "A basic collaborative filtering algorithm, taking into account the z-score normalization of each user.\n",
    "\n",
    "*knns.KNNBaseline*:\n",
    "A basic collaborative filtering algorithm taking into account a baseline rating.\n",
    "\n",
    "*matrix_factorization.SVD*:\n",
    "The famous SVD algorithm, as popularized by Simon Funk during the Netflix Prize.\n",
    "\n",
    "*matrix_factorization.SVDpp*:\n",
    "The SVD++ algorithm, an extension of SVD taking into account implicit ratings.\n",
    "\n",
    "*matrix_factorization.NMF*:\n",
    "A collaborative filtering algorithm based on Non-negative Matrix Factorization.\n",
    "\n",
    "*slope_one.SlopeOne*:\n",
    "A simple yet accurate collaborative filtering algorithm.\n",
    "\n",
    "*co_clustering.CoClustering*:\n",
    "A collaborative filtering algorithm based on co-clustering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is possible to pass a custom dataframe as an argument to this class. The dataframe in question needs to have 3 columns with the following name: ['userID', 'itemID', 'rating']."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-12T22:03:58.167821Z",
     "start_time": "2022-12-12T22:03:58.129369Z"
    }
   },
   "outputs": [],
   "source": [
    "class Method:\n",
    "    def __init__(self,df):\n",
    "        \n",
    "        self.df=df\n",
    "        self.available_methods=[\n",
    "            'surprise.NormalPredictor',\n",
    "            'surprise.BaselineOnly',\n",
    "            'surprise.KNNBasic',\n",
    "            'surprise.KNNWithMeans',\n",
    "            'surprise.KNNWithZScore',\n",
    "            'surprise.KNNBaseline',\n",
    "            'surprise.SVD',\n",
    "            'surprise.SVDpp',\n",
    "            'surprise.NMF',\n",
    "            'surprise.SlopeOne',\n",
    "            'surprise.CoClustering',\n",
    "        ]        \n",
    "        \n",
    "    def show_methods(self):\n",
    "        print('The avaliable methods are:')\n",
    "        for i,method in enumerate(self.available_methods):\n",
    "            print(str(i)+': '+method)\n",
    "\n",
    "\n",
    "\n",
    "    def run(self,the_method):\n",
    "        self.the_method=the_method\n",
    "        if(self.the_method[0:8]=='surprise'):\n",
    "            self.run_surprise()\n",
    "        elif(self.the_method[0:6]=='Gensim'):\n",
    "            self.run_gensim()\n",
    "        elif(self.the_method[0:13]=='Transformers-'):\n",
    "            self.run_transformers()\n",
    "        else:\n",
    "            print('This method is not defined! Try another one.')\n",
    "\n",
    "    def run_surprise(self):\n",
    "        from surprise import Reader\n",
    "        from surprise import Dataset\n",
    "        from surprise.model_selection import train_test_split\n",
    "        reader = Reader(rating_scale=(1, 5))\n",
    "        data = Dataset.load_from_df(self.df[['userID', 'itemID', 'rating']], reader)        \n",
    "        trainset, testset = train_test_split(data, test_size=.30)\n",
    "        the_method=self.the_method.replace(\"surprise.\", \"\")\n",
    "        eval(f\"exec('from surprise import {the_method}')\")\n",
    "        the_algorithm=locals()[the_method]()\n",
    "        the_algorithm.fit(trainset)\n",
    "        self.predictions=the_algorithm.test(testset)\n",
    "        list_predictions=[(uid,iid,r_ui,est) for uid,iid,r_ui,est,_ in self.predictions]        \n",
    "        self.predictions_df = pd.DataFrame(list_predictions, columns =['user_id', 'item_id', 'rating','predicted_rating'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Evaluator class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *surprise* library provides 4 different methods to assess the accuracy of the ratings prediction. For further discussion on each metric please visit the [package documentation](https://surprise.readthedocs.io/en/stable/accuracy.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-12T22:03:58.199931Z",
     "start_time": "2022-12-12T22:03:58.171813Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "class Evaluator:\n",
    "\n",
    "    def __init__(self,predictions_df):\n",
    "\n",
    "        self.available_evaluators=['surprise.rmse','surprise.mse',\n",
    "                                   'surprise.mae','surprise.fcp']\n",
    "        self.predictions_df=predictions_df\n",
    "        \n",
    "    def show_evaluators(self):\n",
    "        print('The avaliable evaluators are:')\n",
    "        for i,evaluator in enumerate(self.available_evaluators):\n",
    "            print(str(i)+': '+evaluator)\n",
    "        \n",
    "\n",
    "\n",
    "    def run(self,the_evaluator):        \n",
    "        self.the_evaluator=the_evaluator\n",
    "        if(self.the_evaluator[0:8]=='surprise'):\n",
    "            self.run_surprise()\n",
    "        else:\n",
    "            print('This evaluator is not available!')\n",
    "\n",
    "    def run_surprise(self):\n",
    "        import surprise\n",
    "        from surprise import accuracy\n",
    "        predictions=[surprise.prediction_algorithms.predictions.Prediction(row['user_id'],row['item_id'],row['rating'],row['predicted_rating'],{}) for index,row in self.predictions_df.iterrows()]\n",
    "        self.predictions=predictions\n",
    "        self.the_evaluator= 'accuracy.' + self.the_evaluator.replace(\"surprise.\", \"\")\n",
    "        self.acc = eval(f'{self.the_evaluator}(predictions,verbose=True)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-12T22:04:10.913854Z",
     "start_time": "2022-12-12T22:03:58.199931Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The avaliable database are:\n",
      "0: ml_100k\n",
      "1: ml_1m\n",
      "2: jester\n",
      "3: lda_topics\n",
      "4: lda_rankings\n",
      "5: uniform\n",
      "The avaliable methods are:\n",
      "0: surprise.NormalPredictor\n",
      "1: surprise.BaselineOnly\n",
      "2: surprise.KNNBasic\n",
      "3: surprise.KNNWithMeans\n",
      "4: surprise.KNNWithZScore\n",
      "5: surprise.KNNBaseline\n",
      "6: surprise.SVD\n",
      "7: surprise.SVDpp\n",
      "8: surprise.NMF\n",
      "9: surprise.SlopeOne\n",
      "10: surprise.CoClustering\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "The avaliable evaluators are:\n",
      "0: surprise.rmse\n",
      "1: surprise.mse\n",
      "2: surprise.mae\n",
      "3: surprise.fcp\n",
      "MSE: 0.9224\n"
     ]
    }
   ],
   "source": [
    "data=Data()\n",
    "data.show_available_databases()\n",
    "data.read_data('ml_100k')\n",
    "method=Method(data.df)  \n",
    "method.show_methods()\n",
    "method.run('surprise.KNNWithMeans')\n",
    "predictions_df=method.predictions_df\n",
    "evaluator=Evaluator(predictions_df)\n",
    "evaluator.show_evaluators()\n",
    "evaluator.run('surprise.mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-12T22:06:16.896426Z",
     "start_time": "2022-12-12T22:04:10.915920Z"
    },
    "run_control": {
     "marked": true
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vitor\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:47: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 5000/5000 [00:25<00:00, 197.66it/s]\n",
      "C:\\Users\\vitor\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:47: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
     ]
    }
   ],
   "source": [
    "def model_table(label):\n",
    "    \n",
    "    '''\n",
    "    Code that builds the table with the accuracy metrics for all rating prediction\n",
    "    models built-in the surprise package. The expected return of this function\n",
    "    is a pandas dataframe (11x4) corresponding to the 11 classifier models and\n",
    "    4 different accuracy metrics.\n",
    "    '''\n",
    "    \n",
    "    import tqdm\n",
    "    \n",
    "    table = pd.DataFrame()\n",
    "    \n",
    "    data=Data()\n",
    "    data.read_data(label)\n",
    "    \n",
    "    method=Method(data.df)\n",
    "    \n",
    "    \n",
    "    for m in method.available_methods:\n",
    "        print(m)\n",
    "        method.run(m)\n",
    "        predictions_df=method.predictions_df\n",
    "        evaluator=Evaluator(predictions_df)\n",
    "        \n",
    "        metrics = []\n",
    "        \n",
    "        for e in evaluator.available_evaluators:\n",
    "            evaluator.run(e)\n",
    "            metrics.append(evaluator.acc)\n",
    "            \n",
    "        table = table.append(dict(zip(evaluator.available_evaluators,metrics)),ignore_index=True)\n",
    "        \n",
    "    table.index = [x[9:] for x in method.available_methods]\n",
    "    table.columns = [x[9:].upper() for x in evaluator.available_evaluators]\n",
    "            \n",
    "    return table\n",
    "\n",
    "\n",
    "import sys, os\n",
    "\n",
    "sys.stdout = open(os.devnull, 'w') # Codigo para desativar os prints\n",
    "\n",
    "uniform = model_table('uniform')  \n",
    "#topics = model_table('lda_topics')\n",
    "ranking = model_table('lda_rankings')\n",
    "\n",
    "sys.stdout = sys.__stdout__ # Codigo para reativar os prints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-12T22:06:16.943394Z",
     "start_time": "2022-12-12T22:06:16.898483Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>FCP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NormalPredictor</th>\n",
       "      <td>1.804259</td>\n",
       "      <td>3.255350</td>\n",
       "      <td>1.467780</td>\n",
       "      <td>0.494004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaselineOnly</th>\n",
       "      <td>1.205625</td>\n",
       "      <td>1.453532</td>\n",
       "      <td>0.992576</td>\n",
       "      <td>0.511330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNNBasic</th>\n",
       "      <td>1.369231</td>\n",
       "      <td>1.874793</td>\n",
       "      <td>1.042901</td>\n",
       "      <td>0.609958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNNWithMeans</th>\n",
       "      <td>1.147743</td>\n",
       "      <td>1.317314</td>\n",
       "      <td>0.838187</td>\n",
       "      <td>0.648390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNNWithZScore</th>\n",
       "      <td>1.152362</td>\n",
       "      <td>1.327938</td>\n",
       "      <td>0.839331</td>\n",
       "      <td>0.663553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNNBaseline</th>\n",
       "      <td>1.197815</td>\n",
       "      <td>1.434760</td>\n",
       "      <td>0.891482</td>\n",
       "      <td>0.637661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVD</th>\n",
       "      <td>0.938683</td>\n",
       "      <td>0.881125</td>\n",
       "      <td>0.700552</td>\n",
       "      <td>0.755073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVDpp</th>\n",
       "      <td>0.932690</td>\n",
       "      <td>0.869911</td>\n",
       "      <td>0.652858</td>\n",
       "      <td>0.748874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NMF</th>\n",
       "      <td>1.202484</td>\n",
       "      <td>1.445968</td>\n",
       "      <td>0.784358</td>\n",
       "      <td>0.678201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SlopeOne</th>\n",
       "      <td>1.120445</td>\n",
       "      <td>1.255398</td>\n",
       "      <td>0.826335</td>\n",
       "      <td>0.668528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CoClustering</th>\n",
       "      <td>1.344250</td>\n",
       "      <td>1.807009</td>\n",
       "      <td>1.033472</td>\n",
       "      <td>0.558972</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     RMSE       MSE       MAE       FCP\n",
       "NormalPredictor  1.804259  3.255350  1.467780  0.494004\n",
       "BaselineOnly     1.205625  1.453532  0.992576  0.511330\n",
       "KNNBasic         1.369231  1.874793  1.042901  0.609958\n",
       "KNNWithMeans     1.147743  1.317314  0.838187  0.648390\n",
       "KNNWithZScore    1.152362  1.327938  0.839331  0.663553\n",
       "KNNBaseline      1.197815  1.434760  0.891482  0.637661\n",
       "SVD              0.938683  0.881125  0.700552  0.755073\n",
       "SVDpp            0.932690  0.869911  0.652858  0.748874\n",
       "NMF              1.202484  1.445968  0.784358  0.678201\n",
       "SlopeOne         1.120445  1.255398  0.826335  0.668528\n",
       "CoClustering     1.344250  1.807009  1.033472  0.558972"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LDA-GENERATED DATASET\n",
    "ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-12T22:06:16.975309Z",
     "start_time": "2022-12-12T22:06:16.947386Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>FCP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NormalPredictor</th>\n",
       "      <td>1.492993</td>\n",
       "      <td>2.229027</td>\n",
       "      <td>1.215566</td>\n",
       "      <td>0.508747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaselineOnly</th>\n",
       "      <td>1.141522</td>\n",
       "      <td>1.303073</td>\n",
       "      <td>1.011387</td>\n",
       "      <td>0.493790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNNBasic</th>\n",
       "      <td>1.215254</td>\n",
       "      <td>1.476843</td>\n",
       "      <td>1.040800</td>\n",
       "      <td>0.489235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNNWithMeans</th>\n",
       "      <td>1.209456</td>\n",
       "      <td>1.462784</td>\n",
       "      <td>1.034739</td>\n",
       "      <td>0.483577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNNWithZScore</th>\n",
       "      <td>1.218065</td>\n",
       "      <td>1.483681</td>\n",
       "      <td>1.045269</td>\n",
       "      <td>0.498226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNNBaseline</th>\n",
       "      <td>1.225382</td>\n",
       "      <td>1.501562</td>\n",
       "      <td>1.048278</td>\n",
       "      <td>0.488941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVD</th>\n",
       "      <td>1.190484</td>\n",
       "      <td>1.417251</td>\n",
       "      <td>1.033332</td>\n",
       "      <td>0.499369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVDpp</th>\n",
       "      <td>1.208144</td>\n",
       "      <td>1.459612</td>\n",
       "      <td>1.036668</td>\n",
       "      <td>0.493682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NMF</th>\n",
       "      <td>1.339499</td>\n",
       "      <td>1.794257</td>\n",
       "      <td>1.117272</td>\n",
       "      <td>0.495636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SlopeOne</th>\n",
       "      <td>1.226202</td>\n",
       "      <td>1.503571</td>\n",
       "      <td>1.047067</td>\n",
       "      <td>0.498251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CoClustering</th>\n",
       "      <td>1.249802</td>\n",
       "      <td>1.562006</td>\n",
       "      <td>1.056043</td>\n",
       "      <td>0.503745</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     RMSE       MSE       MAE       FCP\n",
       "NormalPredictor  1.492993  2.229027  1.215566  0.508747\n",
       "BaselineOnly     1.141522  1.303073  1.011387  0.493790\n",
       "KNNBasic         1.215254  1.476843  1.040800  0.489235\n",
       "KNNWithMeans     1.209456  1.462784  1.034739  0.483577\n",
       "KNNWithZScore    1.218065  1.483681  1.045269  0.498226\n",
       "KNNBaseline      1.225382  1.501562  1.048278  0.488941\n",
       "SVD              1.190484  1.417251  1.033332  0.499369\n",
       "SVDpp            1.208144  1.459612  1.036668  0.493682\n",
       "NMF              1.339499  1.794257  1.117272  0.495636\n",
       "SlopeOne         1.226202  1.503571  1.047067  0.498251\n",
       "CoClustering     1.249802  1.562006  1.056043  0.503745"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BENCHMARK DATASET\n",
    "uniform"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "5fe3e6f0cdaab8afdc61c52912fda83f7c0a71baaea1897dd7498e2df01e69ec"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
